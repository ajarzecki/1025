{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8994ce8-137f-4ede-ab33-2958640f8eda",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d49c763-37db-48ff-9b0b-b51b7f3fb698",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (4.33.1)\n",
      "Requirement already satisfied: datasets in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (2.14.4)\n",
      "Requirement already satisfied: evaluate in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: requests in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: filelock in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from transformers) (0.17.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: xxhash in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from datasets) (2023.9.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: multiprocess in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: pandas in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from datasets) (2.1.0)\n",
      "Requirement already satisfied: aiohttp in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: responses<0.19 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/bartoszpampuch/src/blinkin/llm/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260f87fd-d2cb-4f91-b0c1-98a80a3928ff",
   "metadata": {},
   "source": [
    "Restart Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e5e83-df0d-4e0f-bc80-47fcdd721823",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1199a911-0a8b-4e7b-b984-48c28130600a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb = load_dataset(\"imdb\", split=\"train\")\n",
    "imdb = imdb.train_test_split(test_size=0.025, train_size=0.05, stratify_by_column=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90f24288-55be-4b03-b4b1-81ca7aeb94c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 625\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2d9aced-508c-453e-b357-eb01d934867e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Ugh. This is a terrible film, full of disastrous comic relief, no scares, and scary leaps in story and plotline. The only creepy thing here is the leading lady's hats. Lugosi was on his downhill slide and it shows. I give this a 1, and this ain't no fun.\",\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfd53b79-0e3c-4295-821c-1325d4b04a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['neg', 'pos'], id=None)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cc7528-b324-4bdf-a2ab-aed5e4e76f63",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24345f7f-1fbc-4506-8f99-d23bad78393e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d820093-b621-41ca-9c3f-6aae2dfccf7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2023, 2003, 1037, 3231, 1998, 1037, 3722, 2742, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"This is a test and a simple example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cc078d2-a34b-4450-acde-bedd97ec2c6a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████| 25000/25000 [00:02<00:00, 8696.22 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████| 25000/25000 [00:02<00:00, 8526.86 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:05<00:00, 8418.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "imdb_tokenized = imdb.map(lambda item: tokenizer(item[\"text\"], truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b411774-8d10-4bba-b6c6-a48aa957bdd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85edf4f6-f982-4415-ac3a-3a30c9e1c8e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f33d1df9-4e39-4d0c-a93d-f979119a8e21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 2101.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "imdb_tokenized = imdb.map(lambda x: tokenizer(x[\"text\"], truncation=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dadd724-8dac-41ff-ae4c-42cfb1c961f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Label <-> ID mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0deea8db-92ac-4704-a275-218a54da2cce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d495f09b-4f60-4627-b3b9-c2d628b93536",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c9253a7-1c09-4250-ae6e-64717e2956e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832fe80-d243-400a-9738-82298f1f8de7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc0d028c-ec73-4ffb-b1c8-fe845c0ba710",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510ada6a-39c3-46d3-be49-debb5b6190ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6c8c572-f304-4f21-aeda-854ec2a2955a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"out_sentiment_analysis4\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "746cc4de-9bac-4984-a6ab-841834011006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d70d55-a51a-46bf-adb9-450c7a594e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=imdb_tokenized[\"train\"],\n",
    "    eval_dataset=imdb_tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
